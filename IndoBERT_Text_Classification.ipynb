{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRG0Y9Zo5LoS",
        "outputId": "6b68944d-fd89-4523-db0a-cb421831ee55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.22.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.9.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import random\n",
        "import torch\n",
        "from numpy import asarray, ndarray, nonzero\n",
        "from pandas import DataFrame, read_csv\n",
        "from transformers import AutoModel, AutoTokenizer, BatchEncoding, PreTrainedModel, PreTrainedTokenizer"
      ],
      "metadata": {
        "id": "j2mqd0E66Nlt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clear_cache():\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "clear_cache()"
      ],
      "metadata": {
        "id": "T0o0ENp_G10q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CUDA = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "CPU = torch.device(\"cpu\")"
      ],
      "metadata": {
        "id": "vtCxyUB56UME"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seeds are set according to the IndoBERT paper (https://arxiv.org/pdf/2009.05387)"
      ],
      "metadata": {
        "id": "mybSPpPQxUvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set random seeds\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64zXRB7hMwtT",
        "outputId": "cd9d0914-ea02-4bd8-e7ac-57c7d4f4650c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f686936c5f0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Set Up and Mount Google Drive\n",
        "\n",
        "To run this notebook, please do the following first:\n",
        "1. Create a folder called `NLP` in your own Google Drive.\n",
        "2. Copy everything from the following link (https://drive.google.com/drive/folders/1prXBSo990_33GJbsntehgl-FFSPeX7EB?usp=sharing) into your `NLP` folder. Make sure that the folder structure remains unchanged.\n",
        "3. Mount your Google Drive into Colab."
      ],
      "metadata": {
        "id": "g0GhvYrXDBtQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Download the Transformer"
      ],
      "metadata": {
        "id": "EYUFd2AZ6YzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformer_url: str = \"indobenchmark/indobert-base-p2\"\n",
        "tokenizer: PreTrainedTokenizer = AutoTokenizer.from_pretrained(transformer_url)\n",
        "transformer: PreTrainedModel = AutoModel.from_pretrained(transformer_url).to(CUDA)"
      ],
      "metadata": {
        "id": "E4Bh80SY6a0z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load and Examine the Data\n",
        "\n",
        "In this section, we will:\n",
        "- load the training and testing data,\n",
        "- determine what kinds of data preprocessings are we going to do,\n",
        "- store the data as PyTorch `Dataset` objects,\n",
        "- prepare `DataLoader`s for each `Dataset`."
      ],
      "metadata": {
        "id": "n2nBUkB17dpb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. Load the Data\n",
        "\n",
        "*To load the data, you need mount your Google Drive into Colab.*\n",
        "\n",
        "The file `train.csv` is our training data, while `test.csv` is our testing data. Also, classification labels are stored separately in the file `labels.txt`.\n",
        "\n",
        "We will load all 3 files."
      ],
      "metadata": {
        "id": "9ciIWIeCW9gC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df: DataFrame = read_csv(\"/content/drive/MyDrive/NLP/data_worthcheck/train.csv\", index_col=0)\n",
        "test_df: DataFrame = read_csv(\"/content/drive/MyDrive/NLP/data_worthcheck/test.csv\")\n",
        "with open(\"/content/drive/MyDrive/NLP/data_worthcheck/labels.txt\") as f:\n",
        "    labels: list = f.readlines()\n",
        "labels: ndarray = asarray([line.rstrip(\"\\n\") for line in labels])"
      ],
      "metadata": {
        "id": "N3ajz85g7fjz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "nziJEXKdJ3mu",
        "outputId": "5b44a3fb-8ec0-4f39-b5d5-69a43f0c0ec6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text_a label\n",
              "0      betewe buka twitter cuman ngetweet liat home b...    no\n",
              "1      mas piyuuu mugo2 corona tuh mulut tersumpal ma...    no\n",
              "2      e100ss gini buka informasi sejelas nya identit...   yes\n",
              "3      neng solo wes ono terduga corona cobo neng ati...    no\n",
              "4      midiahn nii akun gak takut takut nya isu coron...    no\n",
              "...                                                  ...   ...\n",
              "21596  depok panas ga karuan kereta sampe pasming huj...    no\n",
              "21597  oxfara arie kriting yg lebi goblo nya orang ke...    no\n",
              "21598  virus corona menyaba depok cuci tangan makan n...    no\n",
              "21599  mata sipit tinggal depok udah abis dah bahan c...    no\n",
              "21600       i ak batuk pilek pusing demam anjir ak depok    no\n",
              "\n",
              "[21601 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-277d96bd-59eb-4d48-b474-c107fab1fa03\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_a</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>betewe buka twitter cuman ngetweet liat home b...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mas piyuuu mugo2 corona tuh mulut tersumpal ma...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>e100ss gini buka informasi sejelas nya identit...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neng solo wes ono terduga corona cobo neng ati...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>midiahn nii akun gak takut takut nya isu coron...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21596</th>\n",
              "      <td>depok panas ga karuan kereta sampe pasming huj...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21597</th>\n",
              "      <td>oxfara arie kriting yg lebi goblo nya orang ke...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21598</th>\n",
              "      <td>virus corona menyaba depok cuci tangan makan n...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21599</th>\n",
              "      <td>mata sipit tinggal depok udah abis dah bahan c...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21600</th>\n",
              "      <td>i ak batuk pilek pusing demam anjir ak depok</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21601 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-277d96bd-59eb-4d48-b474-c107fab1fa03')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-277d96bd-59eb-4d48-b474-c107fab1fa03 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-277d96bd-59eb-4d48-b474-c107fab1fa03');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "NZt2HR_oJ5du",
        "outputId": "ff4f0bfa-b3cb-4c84-d0b2-d6ed3d214d68"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 text_a label\n",
              "0                               jek dajal ga depok bang    no\n",
              "1     detikcom untung depok masuk wilayah nya ridwan...    no\n",
              "2     df dom jakarta depok yg gunain vc cabang nya c...    no\n",
              "3                                     your2rl depok jkt    no\n",
              "4     doakan indonesia selamat virus corona pkb depo...   yes\n",
              "...                                                 ...   ...\n",
              "2795  ku tenang2 bae ku sih ya corona nya ga depok k...    no\n",
              "2796  guru hati hati ya virus corona uda indonesia t...   yes\n",
              "2797  4 terawan menyebut virus corona indonesia terd...   yes\n",
              "2798        realffk buhari can t pronounce corona virus    no\n",
              "2799  hadapi wabah corona pemuda muhammadiyah pemeri...   yes\n",
              "\n",
              "[2800 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24de93b3-eccd-4a01-be0b-8867952f41f6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_a</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>jek dajal ga depok bang</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>detikcom untung depok masuk wilayah nya ridwan...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>df dom jakarta depok yg gunain vc cabang nya c...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>your2rl depok jkt</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>doakan indonesia selamat virus corona pkb depo...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2795</th>\n",
              "      <td>ku tenang2 bae ku sih ya corona nya ga depok k...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2796</th>\n",
              "      <td>guru hati hati ya virus corona uda indonesia t...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2797</th>\n",
              "      <td>4 terawan menyebut virus corona indonesia terd...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2798</th>\n",
              "      <td>realffk buhari can t pronounce corona virus</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2799</th>\n",
              "      <td>hadapi wabah corona pemuda muhammadiyah pemeri...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2800 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24de93b3-eccd-4a01-be0b-8867952f41f6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-24de93b3-eccd-4a01-be0b-8867952f41f6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-24de93b3-eccd-4a01-be0b-8867952f41f6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjPjiSVuYOpY",
        "outputId": "a0f29a5b-de84-4da8-b3dd-3b591944cd42"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['no', 'yes'], dtype='<U3')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. Determine What Kinds of Data Preprocessings Are We Going To Do"
      ],
      "metadata": {
        "id": "uzVMA5ubYe5h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.1. Encode labels\n",
        "\n",
        "The labels are 'no' and 'yes'. We will encode 'no' as 0, and 'yes' as 1."
      ],
      "metadata": {
        "id": "-Cm_EIntKQ82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_label(labels, label) -> int:\n",
        "    return nonzero(labels == label)[0][0]"
      ],
      "metadata": {
        "id": "7zuvIEYJ_rOc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for label in labels:\n",
        "    print(f\"- {label} -> {encode_label(labels, label)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVT-Gu-FLooe",
        "outputId": "d353c35a-2369-4b4c-b90b-460f3788c011"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- no -> 0\n",
            "- yes -> 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perfect."
      ],
      "metadata": {
        "id": "1arBEUNCJM49"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2.2. Tokenized Text Truncation/Padding\n",
        "\n",
        "Next, we need to know the max length of our **tokenized** texts."
      ],
      "metadata": {
        "id": "7FH2qd7SKXMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Longest tokenized text length:\")\n",
        "print(f\"- train.csv: {train_df['text_a'].map(lambda x: tokenizer(x, return_tensors='pt').input_ids.size()[1]).max()} tokens\")\n",
        "print(f\"- test.csv: {test_df['text_a'].map(lambda x: tokenizer(x, return_tensors='pt').input_ids.size()[1]).max()} tokens\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeQYUcFVNPoP",
        "outputId": "30f43791-b939-4a77-b9b2-cfaf17b851fc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longest tokenized text length:\n",
            "- train.csv: 1971 tokens\n",
            "- test.csv: 465 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Yikes!* Well, BERT has a max length limit for tokens: `512`. So all texts that are longer than that will have to be **truncated**. Texts that are shorter will also be **padded**. So all texts will be tokenized into `512` tokens."
      ],
      "metadata": {
        "id": "qfSZyxO0RRj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3. Store the Data As PyTorch `Dataset` Objects"
      ],
      "metadata": {
        "id": "31sEA63QUUeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WorthcheckDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df: DataFrame, labels: ndarray) -> None:\n",
        "        super().__init__()\n",
        "        self.df: DataFrame = df\n",
        "        self.labels: ndarray = labels\n",
        "    \n",
        "    def __len__(self) -> int:\n",
        "        return self.df.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx) -> tuple:\n",
        "        return (self.df[\"text_a\"][idx], encode_label(self.labels, self.df[\"label\"][idx]))"
      ],
      "metadata": {
        "id": "JWfqglOI-7-8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset: WorthcheckDataset = WorthcheckDataset(train_df, labels)\n",
        "test_dataset: WorthcheckDataset = WorthcheckDataset(test_df, labels)"
      ],
      "metadata": {
        "id": "DUizBCViUgSG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4. Prepare the `Dataloader`s\n",
        "\n",
        "We need to create dataloaders that will split the dataset into **batches**. According to the creators of IndoBERT (https://arxiv.org/pdf/2009.05387), they used a batch size of `16` for fine-tuning. So our training dataloder will also use a batch size of `16`. Our test dataloader, though, will simply use a batch size of `len(test_dataset)`."
      ],
      "metadata": {
        "id": "SEp9SqmG-1yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader: torch.utils.data.DataLoader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, pin_memory=True)\n",
        "test_dataloader: torch.utils.data.DataLoader = torch.utils.data.DataLoader(test_dataset, batch_size=(len(test_dataset) // 10), pin_memory=True)"
      ],
      "metadata": {
        "id": "bzbdUJYPF0e8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Define Model\n",
        "\n",
        "Our model has two main parts:\n",
        "- Transformer\n",
        "- Classifier\n",
        "\n",
        "The transformer's role is to encode texts into ~vectors~ tensors. The classifier will then learn to extract features from said tensors."
      ],
      "metadata": {
        "id": "rXIiZJ0Lu6cU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBinaryClassifier(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, transformer: PreTrainedModel) -> None:\n",
        "        super().__init__()\n",
        "        self.transformer: PreTrainedModel = transformer\n",
        "        self.classifier: torch.nn.Sequential = torch.nn.Sequential(\n",
        "            torch.nn.Linear(transformer.config.hidden_size, 1),\n",
        "            torch.nn.Sigmoid()\n",
        "        )\n",
        "    \n",
        "    def forward(self, x: BatchEncoding) -> torch.Tensor:\n",
        "        z: torch.Tensor = self.transformer(**x)\n",
        "        y_tilde: torch.Tensor = self.classifier(z.pooler_output)\n",
        "        return y_tilde"
      ],
      "metadata": {
        "id": "m_2PDpXuyeTH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model: TransformerBinaryClassifier = TransformerBinaryClassifier(transformer)\n",
        "criterion: torch.nn.Module = torch.nn.BCELoss()"
      ],
      "metadata": {
        "id": "CUycTJ78AOlb"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Fine-tune the Model"
      ],
      "metadata": {
        "id": "ohaaCSwktaDc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1. Define Training and Testing Loops"
      ],
      "metadata": {
        "id": "B3j6RN9IKsjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(dataloader: torch.utils.data.DataLoader, tokenizer: PreTrainedTokenizer, model: torch.nn.Module, criterion: torch.nn.Module, optimizer: torch.optim.Optimizer) -> tuple:\n",
        "  \n",
        "    # set model to training mode\n",
        "    model.to(CUDA).train()\n",
        "\n",
        "    # log\n",
        "    epoch_loss: float = 0\n",
        "    epoch_correct: int = 0\n",
        "    epoch_count: int = 0\n",
        "\n",
        "    # load a batch of data\n",
        "    for X, y in dataloader:\n",
        "\n",
        "        # move to GPU\n",
        "        Z: torch.Tensor = tokenizer(list(X), padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\").to(CUDA)\n",
        "        y: torch.Tensor = y.view(-1, 1).to(torch.float).to(CUDA)\n",
        "\n",
        "        # forward pass\n",
        "        y_tilde: torch.Tensor = model(Z)\n",
        "        loss: float = criterion(y_tilde, y)\n",
        "\n",
        "        # backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # log\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_correct += (y_tilde.round() == y).sum().item()\n",
        "        epoch_count += y.size(dim=0)\n",
        "        clear_cache()\n",
        "    \n",
        "    # return log\n",
        "    return (epoch_loss, epoch_correct, epoch_count)"
      ],
      "metadata": {
        "id": "CS5Z-HxUtWul"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(dataloader: torch.utils.data.DataLoader, tokenizer: PreTrainedTokenizer, model: torch.nn.Module, criterion: torch.nn.Module) -> tuple:\n",
        "  \n",
        "    # set model to test mode\n",
        "    model.to(CUDA).eval()\n",
        "\n",
        "    # log\n",
        "    epoch_loss: float = 0\n",
        "    epoch_correct: int = 0\n",
        "    epoch_count: int = 0\n",
        "\n",
        "    # load a batch of data\n",
        "    for X, y in dataloader:\n",
        "\n",
        "        # move to GPU\n",
        "        Z: torch.Tensor = tokenizer(list(X), padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\").to(CUDA)\n",
        "        y: torch.Tensor = y.view(-1, 1).to(torch.float).to(CUDA)\n",
        "\n",
        "        # forward pass\n",
        "        with torch.no_grad():\n",
        "            y_tilde: torch.Tensor = model(Z)\n",
        "            loss: float = criterion(y_tilde, y)\n",
        "\n",
        "        # log\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_correct += (y_tilde.round() == y).sum().item()\n",
        "        epoch_count += y.size(dim=0)\n",
        "        clear_cache()\n",
        "    \n",
        "    # return log\n",
        "    return (epoch_loss, epoch_correct, epoch_count)"
      ],
      "metadata": {
        "id": "oWL1DjhiyOBN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2. Configure Training Hyperparameters"
      ],
      "metadata": {
        "id": "Kpcz7NEFK4J6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again, we match these with the IndoBERT paper (https://arxiv.org/pdf/2009.05387)."
      ],
      "metadata": {
        "id": "HAgjcRP-LCwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs: int = 25\n",
        "learning_rate: float = 4e-5\n",
        "optimizer: torch.optim.Optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "1b6IHrevK_0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3. Train and Save the Best and Final Models\n",
        "\n",
        "*The models are saved into (and subsequently, loaded from) Google Drive. When saving, any previously saved models created from this notebook will be overwritten.*"
      ],
      "metadata": {
        "id": "W3TrbJdiLyXC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_loss: float = float(\"inf\")\n",
        "for i_epoch in range(n_epochs):\n",
        "    epoch_loss, epoch_correct, epoch_count = fit(train_dataloader, tokenizer, model, criterion, optimizer)\n",
        "    print(f\"Epoch [{i_epoch + 1}/{n_epochs}], loss: {epoch_loss}, accuracy: {epoch_correct / epoch_count} ({epoch_correct}/{epoch_count})\")\n",
        "    if epoch_loss < best_loss:\n",
        "        torch.save(model.state_dict(), f\"/content/drive/MyDrive/NLP/models/best/indobert_classifier{i_epoch + 1}.pt\")\n",
        "        best_loss = epoch_loss\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/NLP/models/final/indobert_classifier_final.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTdhoSHLL1Qi",
        "outputId": "b0937127-12ba-461c-f4b6-e1eca88fba45"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/25], loss: 413.94131806865335, accuracy: 0.8742187861673071 (18884/21601)\n",
            "Epoch [2/25], loss: 307.47342503722757, accuracy: 0.9136151104115551 (19735/21601)\n",
            "Epoch [3/25], loss: 227.05701800296083, accuracy: 0.9386139530577288 (20275/21601)\n",
            "Epoch [4/25], loss: 160.79203585302457, accuracy: 0.9604184991435581 (20746/21601)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sadly, we lost the 4th epoch model because our web browser crashed. We then continue fine-tuning using the saved 3rd epoch model."
      ],
      "metadata": {
        "id": "J3OHR1CVs3KJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/NLP/models/best/indobert_classifier3.pt\"))\n",
        "optimizer: torch.optim.Optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "best_loss: float = float(\"inf\")\n",
        "for i_epoch in range(3, n_epochs):\n",
        "    epoch_loss, epoch_correct, epoch_count = fit(train_dataloader, tokenizer, model, criterion, optimizer)\n",
        "    print(f\"Epoch [{i_epoch + 1}/{n_epochs}], loss: {epoch_loss}, accuracy: {epoch_correct / epoch_count} ({epoch_correct}/{epoch_count})\")\n",
        "    if epoch_loss < best_loss:\n",
        "        torch.save(model.state_dict(), f\"/content/drive/MyDrive/NLP/models/best/indobert_classifier{i_epoch + 1}.pt\")\n",
        "        best_loss = epoch_loss\n",
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/NLP/models/final/indobert_classifier_final.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bFxANmd_IvV",
        "outputId": "91aabef3-9201-404c-bff7-f97e2270d919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/25], loss: 178.99997822847217, accuracy: 0.9578723207258923 (20691/21601)\n",
            "Epoch [5/25], loss: 147.40243205893785, accuracy: 0.9660663858154716 (20868/21601)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the 5th epoch, we had to stop fine-tuning because we've hit Google Colab's GPU usage limit (fine-tuning for 1 epoch takes approximately 35 minutes)."
      ],
      "metadata": {
        "id": "XcO77ycjtPT4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Test the Saved Models on the Test Set\n",
        "\n",
        "Using Google Colab CPU instance, we are able to test the saved models on the test set. Each test takes about 1 hour and 40 minutes (because we use a CPU instance).\n",
        "\n",
        "*Again, the models are loaded from Google Drive.*"
      ],
      "metadata": {
        "id": "sNuce2BYtnMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i_epoch in range(5):\n",
        "    model.load_state_dict(torch.load(f\"/content/drive/MyDrive/NLP/models/best/indobert_classifier{i_epoch + 1}.pt\", map_location=CUDA))\n",
        "    epoch_loss, epoch_correct, epoch_count = evaluate(test_dataloader, tokenizer, model, criterion)\n",
        "    print(f\"Epoch {i_epoch + 1} model, test set loss: {epoch_loss}, accuracy: {epoch_correct / epoch_count} ({epoch_correct}/{epoch_count})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-i2kvFcKtsIV",
        "outputId": "191edae8-3da6-43c9-e3d5-af41af2786a1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 model, test set loss: 3.000379726290703, accuracy: 0.8785714285714286 (2460/2800)\n",
            "Epoch 2 model, test set loss: 3.3991998434066772, accuracy: 0.865 (2422/2800)\n",
            "Epoch 3 model, test set loss: 3.348657712340355, accuracy: 0.8760714285714286 (2453/2800)\n",
            "Epoch 4 model, test set loss: 4.028535783290863, accuracy: 0.86 (2408/2800)\n",
            "Epoch 5 model, test set loss: 5.872631788253784, accuracy: 0.7696428571428572 (2155/2800)\n"
          ]
        }
      ]
    }
  ]
}